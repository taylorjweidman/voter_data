{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data 4 | kNN\n",
    "\n",
    "This defines a neighborhood of the k nearest neighbors for every voter in the state and assigns to each voter the composition of this neighborhood. Since this is prohibitive, the main optimization uses the square neighborhoods to partition the matrix. This is done by computing the population of square partitions which have their centroid within some increasing radius. Then the knn algorithm runs over these selected partitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC | 2000m\n",
      "20101102 @ 10050k\n",
      "  Done\n",
      "20110101 @ 10050k\n",
      "  Done\n",
      "20121106 @ 10050k\n",
      "  Done\n",
      "20130101 @ 10050k\n",
      "  Done\n",
      "20141231 @ 10050k\n",
      "  Done\n",
      "20151103 @ 10050k\n",
      "  Done\n",
      "20161108 @ 10050k\n",
      "  Done\n",
      "20171107 @ 10050k\n",
      "  Done\n",
      "20181106 @ 10050k\n",
      "  Done\n",
      "20191105 @ 10050k\n",
      "  Done\n",
      "20201103 @ 10050k\n",
      "  Step 1 | Proximity Matrix (Runtime: 0 mins)\n",
      "  Step 2 | Run KNN by Neighborhood (Runtime: 1936 mins)\n",
      "  Step 3 | Saving\n",
      "     20201103_chunk_8.pkl\n",
      "     20201103_chunk_9.pkl\n",
      "     20201103_chunk_14.pkl\n",
      "     20201103_chunk_2.pkl\n",
      "     20201103_chunk_6.pkl\n",
      "     20201103_chunk_0.pkl\n",
      "     20201103_chunk_7.pkl\n",
      "     20201103_chunk_12.pkl\n",
      "     20201103_chunk_13.pkl\n",
      "     20201103_chunk_10.pkl\n",
      "     20201103_chunk_15.pkl\n",
      "     20201103_chunk_3.pkl\n",
      "     20201103_chunk_11.pkl\n",
      "     20201103_chunk_4.pkl\n",
      "     20201103_chunk_5.pkl\n",
      "     20201103_chunk_1.pkl\n"
     ]
    }
   ],
   "source": [
    "from data4_knn import *\n",
    "\n",
    "T0 = time.time()\n",
    "data_name = f'{state} | {meters}m'\n",
    "print_log[data_name] = {'log':[]}\n",
    "printer(print_log)\n",
    "\n",
    "use_dates = sorted([date for date in dates if int(date[:4]) >= 2010])\n",
    "for date in use_dates:\n",
    "    data_name = f'{date} @ {k_max}k'\n",
    "    save_name = f'{date}_{k_max}k.pkl'\n",
    "    print_log[data_name] = {'log':[],'sublog':[]}\n",
    "    printer(print_log)\n",
    "    \n",
    "    \"\"\" Check If All Chunks Exist \"\"\"\n",
    "    \n",
    "    chunk_nums = [x.strip(date) for x in os.listdir(path_1) if date+'_' in x]\n",
    "    future_files = [f'knn_{date}_{k_max}k{chunk}' for chunk in chunk_nums]\n",
    "    all_files_finished = all([file in os.listdir(path_4 + 'chunks') for file in future_files])\n",
    "\n",
    "    if all_files_finished:\n",
    "        print_log[data_name]['log'].append('  Done')\n",
    "        printer(print_log)\n",
    "        \n",
    "    else:\n",
    "        \"\"\" Step 1 | Proximity Matrix \"\"\"\n",
    "        \n",
    "        t0 = time.time()\n",
    "        print_log[data_name]['log'].append('  Step 1 | Proximity Matrix')\n",
    "        printer(print_log)\n",
    "        \n",
    "        with open(path_3 + f'SNd_{date}_{meters}m.pkl','rb') as f: \n",
    "            SNd = pickle.load(f)\n",
    "        \n",
    "        Pd, POPd = proximity_matrix(SNd, date, print_log)\n",
    "        runtime = round(( time.time() - t0 ) / 60 )\n",
    "        print_log[data_name]['log'][-1] = f'  Step 1 | Proximity Matrix (Runtime: {runtime} mins)'\n",
    "\n",
    "        \"\"\" Step 2 | Run KNN by Neighborhood \"\"\"\n",
    "        \n",
    "        t0 = time.time()\n",
    "        print_log[data_name]['log'].append('  Step 2 | Run KNN by Neighborhood')\n",
    "        printer(print_log)\n",
    "\n",
    "        def ni_knn(ni, run_NVId=False):\n",
    "            \"\"\" Run find the statistics of the nearest k neighbors. \"\"\"\n",
    "\n",
    "            n, P, radius = SNd[ni], Pd[ni]['P'], Pd[ni]['radius']\n",
    "            ni_voters = [SNd[p] for p in P if POPd[p]>0] + [n]\n",
    "            ni_voters = pd.concat(ni_voters, ignore_index=True)\n",
    "\n",
    "            n_lat_lon = list(zip(n.lat, n.lon))\n",
    "            ni_v_lat_lon = list(zip(ni_voters.lat, ni_voters.lon))\n",
    "            ni_distances = pd.DataFrame(haversine_vector(ni_v_lat_lon, n_lat_lon, Unit.METERS, comb=True))\n",
    "            ni_distances.columns = ni_voters.idu.values\n",
    "            ni_distances.index = n.idu.values\n",
    "\n",
    "            def vi_knn(n, ni_voters, ni_distances):\n",
    "                \"\"\" Run knn for all voters in n. \"\"\"\n",
    "                \n",
    "                extra_variables = ['white','black',]#'M','F','age']#,'lat','lon','dist']\n",
    "                knn_stats = pd.DataFrame(columns=knn_col_names(extras=extra_variables))\n",
    "                nearest_dict = {}\n",
    "                for vi,v in n.iterrows():\n",
    "                    try: # This is to handle the rare case when there are multiple voters \n",
    "                        v_sorted = ni_distances.loc[v.idu].sort_values()\n",
    "                    except:\n",
    "                        v_sorted = ni_distances.loc[v.idu].iloc[0].sort_values()\n",
    "                    v_0_index = v_sorted[v_sorted == 0].index\n",
    "                    v_0 = ni_voters[ni_voters.idu.isin(v_0_index)]\n",
    "                    v_stats = [sum(v_0[p]) for p in party_list]\n",
    "\n",
    "                    nearest_dict[v.idu] = {}\n",
    "                    for k in k_list:\n",
    "                        v_knn_index = v_sorted[:k].index\n",
    "                        nearest_dict[v.idu][k] = v_knn_index\n",
    "                        v_knn = ni_voters[ni_voters.idu.isin(v_knn_index)]\n",
    "                        v_stats += [sum(v_knn[p]) for p in party_list]\n",
    "                        v_kn_index = v_sorted[k-1:k].index[0]\n",
    "                        v_kn = ni_voters[ni_voters.idu == v_kn_index]\n",
    "                        \n",
    "                        \"\"\" Additional Variables \"\"\"\n",
    "                        if 'white' in extra_variables:\n",
    "                            v_stats += [sum(v_knn['race']=='WHITE')]\n",
    "                        if 'black' in extra_variables:\n",
    "                            v_stats += [sum(v_knn['race']=='BLACK or AFRICAN AMERICAN')]\n",
    "                        if 'M' in extra_variables:\n",
    "                            v_stats += [sum(v_knn.gender == 'M')]\n",
    "                        if 'F' in extra_variables:\n",
    "                            v_stats += [sum(v_knn.gender == 'F')]\n",
    "                        if 'age' in extra_variables:\n",
    "                            v_stats += [v_knn.age.astype(int).mean()]\n",
    "                        if 'lat' in extra_variables:\n",
    "                            v_stats += [v_kn.lat]\n",
    "                        if 'lon' in extra_variables:\n",
    "                            v_stats += [v_kn.lon]\n",
    "                        if 'dist' in extra_variables:\n",
    "                            v_stats += [v_sorted[k-1]]\n",
    "                        \n",
    "                        # include the turnout of the KNN too ... although this might be more costly and involve a choice of which elections\n",
    "                    knn_stats.loc[v.idu] = [v.idu] + v_stats\n",
    "                if run_NVId:\n",
    "                    return knn_stats, nearest_dict\n",
    "                else:\n",
    "                    return knn_stats\n",
    "            return vi_knn(n, ni_voters, ni_distances)\n",
    "\n",
    "        \"\"\" NVId saves the closest neighbors indices. \"\"\"\n",
    "        \n",
    "        NVId, NVId_subsample = {}, [_ for _ in SNd][:1000] # {}, []\n",
    "        \n",
    "        \"\"\" Run KNN. \"\"\"\n",
    "        \n",
    "        KNNd, finished = {}, []\n",
    "        for ni in SNd:\n",
    "            if ni in NVId_subsample:\n",
    "                KNNd[ni], NVId[ni] = ni_knn(ni, run_NVId=True)\n",
    "            else:\n",
    "                KNNd[ni] = ni_knn(ni)\n",
    "            finished.append(ni)\n",
    "\n",
    "            runtime = f'{round( len(finished)*100/len(SNd), 2)}% in {round(( time.time() - t0 ) / 60 )} mins'\n",
    "            print_log[data_name]['sublog'] = [f'   || KNN {runtime}']\n",
    "            printer(print_log)\n",
    "        del SNd\n",
    "        \n",
    "        with open(f'{path_4}NVId_{date}_{k_max}_knn.pkl','wb') as f: \n",
    "            pickle.dump(NVId, f)\n",
    "        del NVId\n",
    "\n",
    "        print_log[data_name]['sublog'] = []\n",
    "        runtime = round(( time.time() - t0 ) / 60 )\n",
    "        print_log[data_name]['log'][-1] = f'  Step 2 | Run KNN by Neighborhood (Runtime: {runtime} mins)'\n",
    "        printer(print_log)\n",
    "\n",
    "        \"\"\" Step 3 | Saving \"\"\"\n",
    "        t0 = time.time()\n",
    "        print_log[data_name]['log'].append('  Step 3 | Saving')\n",
    "        printer(print_log)\n",
    "        \n",
    "        voters = pd.concat(KNNd)\n",
    "        \n",
    "        chunk_files = [chunk for chunk in os.listdir(path_1) if date+'_' in chunk]\n",
    "        for chunk_file in chunk_files:\n",
    "            print('    ', chunk_file)\n",
    "            chunk = pd.read_pickle(path_1 + chunk_file)\n",
    "            knn_chunk = voters.merge(chunk)\n",
    "            \n",
    "            chunk_number = chunk_file.strip('NC' + date)\n",
    "            knn_chunk.to_pickle(path_4 + f'chunks/knn_{date}_{k_max}k{chunk_number}')\n",
    "        \n",
    "        \"\"\" Saving print_log \"\"\"\n",
    "        now = datetime.now()\n",
    "        savedate = ''.join([str(now.year),str(now.strftime('%m')),str(now.strftime('%d'))])\n",
    "        file = open(f'{path_4}print_log_{savedate}.txt', 'w')\n",
    "        file.write(string_printer(print_log))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I ran this after, since I didn't have the 2020 variables when running initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20201103_chunk_8.pkl\n",
      "     20201103_chunk_9.pkl\n",
      "     20201103_chunk_14.pkl\n",
      "     20201103_chunk_2.pkl\n",
      "     20201103_chunk_6.pkl\n",
      "     20201103_chunk_0.pkl\n",
      "     20201103_chunk_7.pkl\n",
      "     20201103_chunk_12.pkl\n",
      "     20201103_chunk_13.pkl\n",
      "     20201103_chunk_10.pkl\n",
      "     20201103_chunk_15.pkl\n",
      "     20201103_chunk_3.pkl\n",
      "     20201103_chunk_11.pkl\n",
      "     20201103_chunk_4.pkl\n",
      "     20201103_chunk_5.pkl\n",
      "     20201103_chunk_1.pkl\n"
     ]
    }
   ],
   "source": [
    "from data4_knn import *\n",
    "\n",
    "date = '20201103'\n",
    "\n",
    "chunk_files = [chunk for chunk in os.listdir(path_1) if date+'_' in chunk]\n",
    "for chunk_file in chunk_files:\n",
    "    print('    ', chunk_file)\n",
    "    \n",
    "    chunk = pd.read_pickle(path_1 + chunk_file)\n",
    "    \n",
    "    chunk_number = chunk_file.strip('NC' + date)\n",
    "    knn_chunk = pd.read_pickle(path_4 + f'chunks/knn_{date}_{k_max}k{chunk_number}')\n",
    "\n",
    "    knn_chunk = knn_chunk.merge(chunk)\n",
    "    \n",
    "    chunk_number = chunk_file.strip('NC' + date)\n",
    "    knn_chunk.to_pickle(path_4 + f'chunks/knn_{date}_{k_max}k{chunk_number}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analysis\n",
    "\n",
    "Visualize a voter's knn map and summarize the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
