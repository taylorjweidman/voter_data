{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data -1 | Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Link KNN with Turnout\n",
    "\n",
    "A list of elections in North Carolina https://en.wikipedia.org/wiki/Elections_in_North_Carolina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_2010\n",
      "  || Done\n",
      "NC_2012\n",
      "  || Done\n",
      "NC_2013\n",
      "  || Done\n",
      "NC_2015\n",
      "  || Done\n",
      "NC_2016\n",
      "  || Done\n",
      "NC_2017\n",
      "  || Done\n",
      "NC_2018\n",
      "  || Done\n",
      "NC_2019\n"
     ]
    }
   ],
   "source": [
    "from datalink import *\n",
    "\n",
    "with open(path_0 + 'turnout_history_20190101.pkl','rb') as f: \n",
    "    history = pickle.load(f)\n",
    "elections = history.election_desc.unique()\n",
    "\n",
    "# 'MUNCIPAL', 'MUNI'\n",
    "# 'EDUCATION'\n",
    "# 'ALCHOHOL', 'BEVERAGE'\n",
    "\n",
    "election_types = ['GENERAL', 'PRIMARY', 'MUNICIPAL',]# 'SCHOOL', 'REFERENDUM', 'MUNI AND SANI DISTRICT', 'ABC']\n",
    "election_types = {election_type: [e for e in elections if election_type in e] for election_type in election_types}\n",
    "\n",
    "\n",
    "files = set([x.split('_chunk_')[0] for x in os.listdir(path_1) if x.split('.')[-1] == 'pkl'])\n",
    "for file in sorted(files):\n",
    "    \n",
    "    state, year = file.split('_')\n",
    "    print(file)\n",
    "    \n",
    "    last_election_type = [e for e in election_types][-1]\n",
    "    if int(year) >= 2019:#year + '_' + last_election_type + '.pkl' not in os.listdir(path_link):\n",
    "    \n",
    "        knn_voters = pd.read_pickle(path_4+'knn_' + year + '_' + str(k_max) + 'k.pkl')\n",
    "        knn_idu_list = knn_voters.idu.unique()\n",
    "        print('  KNN:',len(knn_voters))\n",
    "\n",
    "        for election_type in election_types:\n",
    "            if year + '_' + election_type + '.pkl' not in os.listdir(path_link):\n",
    "                print('  ',election_type)\n",
    "                keep_election_cols = ['voted_' + e for e in election_types[election_type]]\n",
    "\n",
    "                chunk_file_names = [x for x in os.listdir(path_1) if file in x]# x.split('_chunk_')[0] == file]\n",
    "                for chunk_name in sorted(chunk_file_names):\n",
    "                    knn_chunk_name = chunk_name.replace('chunk','knn_' + election_type + '_chunk')\n",
    "\n",
    "                    chunk = pd.read_pickle(path_1 + chunk_name)\n",
    "                    chunk = chunk[['idu'] + keep_election_cols]\n",
    "                    chunk = knn_voters.merge(chunk, on='idu', how='inner')\n",
    "                    \n",
    "                    chunk.to_pickle(path_link + 'chunks/' + knn_chunk_name)\n",
    "                    print('  ||',len(chunk),'voters')\n",
    "\n",
    "            else:\n",
    "                print('  ||',election_type,'Done')\n",
    "        del knn_voters\n",
    "    else:\n",
    "        print('  || Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "election_files = [x for x in os.listdir(linkpath+'turnout') if '_turnout.csv' in x]\n",
    "\n",
    "for e in election_files:\n",
    "    year = str(e)[:4]\n",
    "    turnout = pd.read_csv(linkpath+'turnout/'+e, low_memory=False)\n",
    "    if key+'_knn_'+year+'.csv' in os.listdir(knnpath):\n",
    "        voters = pd.read_csv(knnpath+key+'_knn_'+year+'.csv')\n",
    "        voters = voters[voters.DOUBLE_ID.isin(base_ids)] # look at only voters who COULD appear in the history dataset, those in 2019.\n",
    "\n",
    "        geo = pd.read_csv('../voters/data3_neighborhoods/NC/voters_'+year+'_2000m.csv', low_memory=False)\n",
    "        geo['DOUBLE_ID'] = geo['ID_NUM'].astype(str) + geo['ID_NUM_a'].astype(str)\n",
    "        subgeo = geo[geo.DOUBLE_ID.isin(voters.DOUBLE_ID.unique())]\n",
    "        voters = voters.merge(subgeo[['DOUBLE_ID','PRECINCT']], how='inner', on='DOUBLE_ID')\n",
    "\n",
    "        subturnout = turnout[turnout.DOUBLE_ID.isin(voters.DOUBLE_ID.unique())]\n",
    "        turnout_ids = subturnout.DOUBLE_ID.unique()\n",
    "        def recent_vote(x):\n",
    "            if x in turnout_ids:\n",
    "                return 'VOTED'\n",
    "            else:\n",
    "                return 'ABSTAINED'\n",
    "        recent_vote_list = []\n",
    "        for r in voters.iterrows():\n",
    "            recent_vote_list.append(recent_vote(r[1].DOUBLE_ID))\n",
    "        voters['recent_vote'] = recent_vote_list\n",
    "        voters.to_csv(linkpath+'turnout/'+key+'_knn_'+e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ACS Plus\n",
    "Add ACS interpolated data to knn samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'NC'\n",
    "linkpath = '../voters/data5_link/'+state+'/'\n",
    "\n",
    "with open('../voters/data4_knn/'+state+'/key_id_subsamples.pkl','rb') as f: key_id_subsamples = pickle.load(f)\n",
    "keys = [key for key in key_id_subsamples]\n",
    "datadict = {}\n",
    "link_ids = []\n",
    "for key in keys:\n",
    "    if key+'_plus.csv' in os.listdir(linkpath):\n",
    "        datadict[key] = pd.read_csv(linkpath+key+'_plus.csv', low_memory=False)\n",
    "    else:\n",
    "        datadict[key] = pd.read_csv(linkpath+key+'.csv', low_memory=False)\n",
    "    link_ids = link_ids + list(datadict[key].DOUBLE_ID.unique())\n",
    "link_ids = list(set(link_ids)) # List of subsample DOUBLE_IDS\n",
    "\n",
    "meterlist = [500]#,2000]\n",
    "for meters in meterlist:\n",
    "    datalist = []\n",
    "    for year in nc_yearlist:\n",
    "        with open('../voters/data3_neighborhoods/'+state+'/SNd_'+str(year)+'_'+str(meters)+'m.pkl','rb') as f: SNd = pickle.load(f)\n",
    "        finished = []\n",
    "        for ni in SNd:\n",
    "            n = SNd[ni]\n",
    "            n['YEAR'] = year\n",
    "            n['M_'+str(meters)+'m'] = sum((n.GENDER == 'M')*1)\n",
    "            n['F_'+str(meters)+'m'] = sum((n.GENDER == 'F')*1)\n",
    "            n['BLACK_'+str(meters)+'m'] = sum((n.RACE == 'BLACK or AFRICAN AMERICAN')*1)\n",
    "            n['WHITE_'+str(meters)+'m'] = sum((n.RACE == 'WHITE')*1)\n",
    "            n['OTHER_'+str(meters)+'m'] = sum((~n.RACE.isin(['BLACK or AFRICAN AMERICAN','WHITE']))*1)\n",
    "            n['D_'+str(meters)+'m'] = n.D.sum()\n",
    "            n['R_'+str(meters)+'m'] = n.R.sum()\n",
    "            n['O_'+str(meters)+'m'] = n.O.sum()\n",
    "            n['MEAN_AGE_'+str(meters)+'m'] = n.AGE.astype(float).mean()\n",
    "            print(year,round(len(finished)/len(SNd)*100,2),'%')\n",
    "            clear_output(wait=True)\n",
    "            finished.append(ni)\n",
    "        SNfinal = [SNd[i] for i in SNd]\n",
    "        SNfinal = pd.concat(SNfinal,ignore_index=True, sort=False)\n",
    "        SNfinal['DOUBLE_ID'] = SNfinal['ID_NUM'] + SNfinal['ID_NUM_a']\n",
    "        SNfinal = SNfinal[SNfinal.DOUBLE_ID.isin(link_ids)]\n",
    "        datalist.append(SNfinal)\n",
    "\n",
    "    linkdata = pd.concat(datalist)\n",
    "    linkdata = linkdata.sort_values(by=['DOUBLE_ID','YEAR'])\n",
    "    \n",
    "    keys = ['move','switch','stay','move_switch']\n",
    "    for key in keys:\n",
    "        key_linkdata = linkdata[linkdata.DOUBLE_ID.isin(datadict[key].DOUBLE_ID.unique())]\n",
    "        key_linkdata['DOUBLE_ID_YEAR'] = key_linkdata['DOUBLE_ID'] + '_' + key_linkdata['YEAR'].astype(str)\n",
    "        key_linkdata_droplist = ['ID_NUM','CITY','STATE','ZIP_CODE','ID_NUM_a','GENDER','AGE','RACE','sn_i','lat','lon','YEAR','D','R','O']\n",
    "        key_linkdata_keeplist = [col for col in key_linkdata.columns.values if col not in key_linkdata_droplist]\n",
    "        key_linkdata = key_linkdata[key_linkdata_keeplist]\n",
    "\n",
    "        datadict[key]['DOUBLE_ID_YEAR'] = datadict[key]['DOUBLE_ID'] + '_' + datadict[key]['YEAR'].astype(str)\n",
    "\n",
    "        merge = datadict[key].merge(key_linkdata, left_on='DOUBLE_ID_YEAR', right_on='DOUBLE_ID_YEAR', how='outer')\n",
    "        rename_dict = {x:x.replace('_x','') for x in squares_keep_cols if '_x' in x}\n",
    "        merge = merge.rename(columns=rename_dict)\n",
    "\n",
    "        merge.to_csv('data5_link/NC/'+key+'_plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#autor_variables = ['POP', 'WHITE', 'BLACK', 'VOTING_POP', 'LABOR',\n",
    "#       'COLLEGE', 'COLLEGE_EMPLOYED', 'SOME_COLLEGE',\n",
    "#       'SOME_COLLEGE_EMPLOYED', 'NO_COLLEGE', 'NO_COLLEGE_EMPLOYED',\n",
    "#       'TRANTIME', 'COLLEGE_WAGE', 'SOME_COLLEGE_WAGE', 'NO_COLLEGE_WAGE']\n",
    "#for col in autor_variables:\n",
    "#    move[col+'_past'] = move[col].shift(1)\n",
    "#move = move[move['DOUBLE_ID'] == move['DOUBLE_ID'].shift(1)]\n",
    "#move.to_csv('data5_link/NC/'+keys[0]+'_plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for col in ['DOUBLE_ID','ZIP_CODE','sn_i','lat','lon','D','R','O']:#+return_k_col_names(state):\n",
    "#    colshiftname = col+'_past'\n",
    "#    linkdata[colshiftname] = linkdata[col].shift(1)\n",
    "#linkdata = linkdata[linkdata['DOUBLE_ID'] == linkdata['DOUBLE_ID'].shift(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, time, datetime\n",
    "#date.today()\n",
    "datetime.now().strftime('%H')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
